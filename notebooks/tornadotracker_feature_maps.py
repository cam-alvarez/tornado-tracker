# -*- coding: utf-8 -*-
"""TornadoTracker Feature Maps

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o178C_CcihPKepytHL9mtu-npnC_PWgs
"""

import torch
from torchvision import models, transforms
import requests
from PIL import Image
import torch.nn.functional as F
import matplotlib.pyplot as plt

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

#define alexnet model
alexnet = models.alexnet(pretrained=True).to(device)
labels = {int(key):value for (key, value) in requests.get('https://s3.amazonaws.com/mlpipes/pytorch-quick-start/labels.json').json().items()}

#transform image for use in model
preprocess = transforms.Compose([
   transforms.Resize(256),
   transforms.CenterCrop(224),
   transforms.ToTensor(),
   transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])
])

#load the image from its url
url = 'https://cam-portfolio-blog.netlify.app/tornado1.png'
img = Image.open(requests.get(url, stream=True).raw)

img_t = preprocess(img).unsqueeze_(0).to(device)

img_t.shape

labels

#classify the image with alexnet
scores, class_idx = alexnet(img_t).max(1)
print('Predicted class:', labels[class_idx.item()])

w0 = alexnet.features[0].weight.data
w1 = alexnet.features[3].weight.data
w2 = alexnet.features[6].weight.data
w3 = alexnet.features[8].weight.data
w4 = alexnet.features[10].weight.data
w5 = alexnet.classifier[1].weight.data
w6 = alexnet.classifier[4].weight.data
w7 = alexnet.classifier[6].weight.data

# Save and Load
# w = [w0,w1,w2,w3,w4,w5,w6,w7]
# torch.save(w, 'Hahn_Alex.pt')
# w = torch.load('Hahn_Alex.pt')
# [w0,w1,w2,w3,w4,w5,w6,w7] = w
# [w0,w1,w2,w3,w4,w5,w6,w7] = torch.load('Hahn_Alex.pt')

img_t.shape,w0.shape

img_t.shape

img_t[0,:,:,:].shape



def scale(img):
    # Normalize the NumPy array to the range [0, 1]
    max_value = img.max()
    min_value = img.min()
    normalized_array = (img - min_value) / (max_value - min_value)
    return normalized_array

def tensor_plot(img_t,index=0):
    numpy_array = img_t[index,:,:,:].cpu().numpy()
    numpy_array_transposed = numpy_array.transpose(1, 2, 0)
    numpy_array_transposed = scale(numpy_array_transposed)
    plt.imshow(numpy_array_transposed)
    plt.show()

tensor_plot(img_t)

tensor_plot(w0,0)

tensor_plot(w0,1)

for i in range(64):
    tensor_plot(w0,i)

w0.shape

f0 = F.conv2d(img_t, w0, stride=4, padding=2)

f0.shape

i = 0
plt.imshow(f0[0,i,:,:].cpu().numpy())

for i in range(64):
    tensor_plot(w0,i)
    plt.imshow(f0[0,i,:,:].cpu().numpy())
    plt.show()

f0.shape,w0.shape

plot_feature_maps_with_filters(f0, w0)



f1 = F.relu(f0)

f1.shape

f2 = F.max_pool2d(f1,kernel_size=3, stride=2, padding=0, dilation=1)

f2.shape

i = 0
plt.imshow(f0[0,i,:,:].cpu().numpy())
plt.colorbar()

i = 0
plt.imshow(f1[0,i,:,:].cpu().numpy())
plt.colorbar()

i = 0
plt.imshow(f2[0,i,:,:].cpu().numpy())
plt.colorbar()

f3 = F.conv2d(f2, w1, stride=1, padding=2)

f4 = F.relu(f3)

f5 = F.max_pool2d(f4,kernel_size=3, stride=2, padding=0, dilation=1)

f6 = F.conv2d(f5, w2, stride=1, padding=1)

f7 = F.relu(f6)

f8 = F.conv2d(f7, w3, stride=1, padding=1)

f9 = F.relu(f8)

f10 = F.conv2d(f9, w4, stride=1, padding=1)

f11 = F.relu(f10)

f12 = F.max_pool2d(f11, kernel_size=3, stride=2, padding=0, dilation=1)

f13 = F.adaptive_avg_pool2d(f12,output_size=6).flatten()

f14 = F.linear(f13,w5)

f15 = F.relu(f14)

f16 = F.linear(f15,w6)

f17 = F.relu(f16)

f18 = F.linear(f17,w7)

out = f18.argmax().item()



f18.shape

plt.plot(f18.cpu().numpy())

out

labels

labels[out]

f18.argmax()

labels[522]

